= 3. Context and Scope
:toc: left
:toclevels: 3
:icons: font

== 3.1 Business Context

The system interacts with developers, AI assistants, and local resources (git repositories, LLM models).

[mermaid]
----
graph TB
    subgraph "Users"
        DEV[ðŸ‘¤ Developer]
        AI[ðŸ¤– AI Assistant<br/>Claude, etc.]
    end

    subgraph "DailyStandApp System"
        APP[DailyStandApp]
    end

    subgraph "Local Resources"
        GIT[(Git Repositories)]
        MODEL[(GGUF Models)]
    end

    DEV -->|"CLI"| APP
    AI -->|"MCP Protocol"| APP
    APP -->|"Read commits"| GIT
    APP -->|"Load weights"| MODEL
    APP -->|"Summaries"| DEV
    APP -->|"Tool results"| AI

    style DEV fill:#e3f2fd
    style AI fill:#f3e5f5
    style APP fill:#fff3e0
    style GIT fill:#e8f5e9
    style MODEL fill:#fce4ec
----

=== External Interfaces

[cols="1,2,3"]
|===
|Interface |Partner |Description

|*CLI*
|Developer
|Command-line interface for scripted use

|*MCP Protocol*
|AI Assistant
|Model Context Protocol over stdio transport

|*File System*
|Git Repository
|JGit library reads local `.git` directories

|*File System*
|GGUF Model
|SKaiNET loads quantized model files

|*REST API*
|Cloud API Client / External Consumers
|OpenAI-compatible HTTP API (`/v1/chat/completions`, `/v1/models`) via cloud-api server module
|===

== 3.2 Technical Context

[mermaid]
----
flowchart LR
    subgraph "Client Layer"
        CLAUDE[Claude Desktop]
        TERMINAL[Terminal]
    end

    subgraph "DailyStandApp"
        subgraph "Entry Points"
            MCP[MCP Server<br/>stdio]
            CLI[CLI<br/>args]
            BENCH[Benchmark<br/>CLI]
        end

        subgraph "Core"
            LLM[LLM Module]
            DATA[Data Module]
        end

        subgraph "Cloud API"
            APISERVER[Cloud API Server<br/>OpenAI-compatible]
            APICLIENT[Cloud API Client]
        end
    end

    subgraph "Infrastructure"
        GIT[(Git Repo<br/>JGit)]
        GGUF[(Model<br/>GGUF)]
    end

    CLAUDE -->|"JSON-RPC/stdio"| MCP
    TERMINAL -->|"args"| CLI
    TERMINAL -->|"args"| BENCH
    TERMINAL -->|"HTTP REST"| APISERVER

    MCP --> LLM
    MCP --> DATA
    CLI --> LLM
    CLI --> DATA
    BENCH --> LLM
    APICLIENT --> APISERVER

    DATA -->|"org.eclipse.jgit"| GIT
    LLM -->|"SKaiNET kllama"| GGUF
----

=== Communication Channels

[cols="1,1,2,2"]
|===
|Channel |Protocol |Technology |Data Format

|MCP Server
|JSON-RPC 2.0
|MCP Kotlin SDK + Stdio
|JSON with tool schemas

|CLI
|Process Args
|JVM Main
|Text output

|Benchmark
|Process Args + Env Vars
|JVM Main
|Markdown report + CSV

|Git Access
|File System
|Eclipse JGit
|Git objects

|Model Loading
|File System
|SKaiNET I/O
|GGUF binary format

|Cloud API
|HTTP REST
|Ktor Server/Client
|OpenAI-compatible JSON
|===

== 3.3 Data Flow Overview

[mermaid]
----
flowchart TD
    subgraph "Input"
        REQ[Request<br/>repo, dates, author]
    end

    subgraph "Processing"
        FETCH[Fetch Commits<br/>JGit]
        FORMAT[Format for LLM]
        INFER[LLM Inference<br/>kllama]
    end

    subgraph "Output"
        SUMMARY[Standup Summary]
    end

    REQ --> FETCH
    FETCH --> FORMAT
    FORMAT --> INFER
    INFER --> SUMMARY

    style REQ fill:#e3f2fd
    style SUMMARY fill:#c8e6c9
----
